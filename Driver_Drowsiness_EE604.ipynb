{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "bblDszi37HMM",
        "outputId": "12af39e8-6b95-42c3-c80d-945c17a468a5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediapipe'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2966929002.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\"\"\"\n",
        "Driver Drowsiness Detection using EAR / I-EAR style approach\n",
        "- Works with webcam or pre-recorded video\n",
        "- Uses MediaPipe Face Mesh for facial landmarks\n",
        "- Triggers alarm if eyes closed for too long OR blink rate too low\n",
        "- Low-latency yawning detection (fires DURING a sustained mouth-open)\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import deque\n",
        "import threading\n",
        "import os\n",
        "\n",
        "# -------------------- Config --------------------\n",
        "USE_VIDEO_FILE = False\n",
        "VIDEO_FILE = \"sample_driver.mp4\"  # path to your test video\n",
        "\n",
        "CAMERA_INDEX = 0\n",
        "FRAME_WIDTH = 640\n",
        "FRAME_HEIGHT = 480\n",
        "FPS = 15  # will update if camera reports real fps\n",
        "\n",
        "# Drowsiness thresholds (from paper)\n",
        "LONG_FRAME_THRESHOLD = 40        # frames eyes continuously closed\n",
        "BLINKS_PER_MIN_THRESHOLD = 8     # blinks per minute below this = drowsy\n",
        "\n",
        "SMOOTHING_WINDOW = 5\n",
        "BLINK_WINDOW_SECONDS = 60\n",
        "BLINK_DETECTION_EAR_THRESHOLD = 0.21\n",
        "MIN_BEEP_INTERVAL = 5  # seconds between alarms (general)\n",
        "# ------------------------------------------------\n",
        "\n",
        "# ------------- Low-latency yawn detection ---------------\n",
        "MAR_SMOOTHING_WINDOW = 3\n",
        "MAR_BASELINE_WINDOW = 150\n",
        "MAR_DELTA = 0.14          # margin over baseline\n",
        "MAR_FLOOR = 0.50          # absolute minimum threshold\n",
        "MAR_HYST = 0.03           # hysteresis to avoid flicker\n",
        "YAWN_MIN_DURATION = 0.5   # seconds of sustained open to trigger\n",
        "MIN_BEEP_INTERVAL_YAWN = 2  # seconds between yawn alarms (faster)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# MediaPipe indices for eyes\n",
        "LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE_IDX = [263, 387, 385, 362, 380, 373]\n",
        "\n",
        "# MediaPipe indices for mouth (corners + inner lips)\n",
        "MOUTH_LEFT_CORNER = 61\n",
        "MOUTH_RIGHT_CORNER = 291\n",
        "MOUTH_UPPER_INNER = 13\n",
        "MOUTH_LOWER_INNER = 14\n",
        "\n",
        "def dist(p, q):\n",
        "    return np.linalg.norm(np.array(p) - np.array(q))\n",
        "\n",
        "def eye_aspect_ratio(landmarks, eye_idx):\n",
        "    p1 = landmarks[eye_idx[0]]\n",
        "    p2 = landmarks[eye_idx[1]]\n",
        "    p3 = landmarks[eye_idx[2]]\n",
        "    p4 = landmarks[eye_idx[3]]\n",
        "    p5 = landmarks[eye_idx[4]]\n",
        "    p6 = landmarks[eye_idx[5]]\n",
        "    vert1 = dist(p2, p6)\n",
        "    vert2 = dist(p3, p5)\n",
        "    horiz = dist(p1, p4)\n",
        "    if horiz == 0:\n",
        "        return 0.0\n",
        "    return (vert1 + vert2) / (2.0 * horiz)\n",
        "\n",
        "def mouth_aspect_ratio(landmarks):\n",
        "    p_left  = landmarks[MOUTH_LEFT_CORNER]\n",
        "    p_right = landmarks[MOUTH_RIGHT_CORNER]\n",
        "    p_up    = landmarks[MOUTH_UPPER_INNER]\n",
        "    p_low   = landmarks[MOUTH_LOWER_INNER]\n",
        "    horiz = dist(p_left, p_right)\n",
        "    vert  = dist(p_up, p_low)\n",
        "    return 0.0 if horiz == 0 else vert / horiz\n",
        "\n",
        "def play_alarm_thread(_=None):\n",
        "    try:\n",
        "        # macOS voice alert\n",
        "        os.system(\"say 'You are drowsy'\")\n",
        "        # Alternative: system sound\n",
        "        # os.system(\"afplay /System/Library/Sounds/Glass.aiff\")\n",
        "    except Exception as e:\n",
        "        print(\"[ALARM] YOU ARE DROWSY!\", e)\n",
        "\n",
        "def main():\n",
        "    if USE_VIDEO_FILE:\n",
        "        cap = cv2.VideoCapture(VIDEO_FILE)\n",
        "    else:\n",
        "        cap = cv2.VideoCapture(CAMERA_INDEX)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
        "\n",
        "    actual_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    global FPS\n",
        "    if actual_fps and actual_fps > 0:\n",
        "        FPS = actual_fps\n",
        "\n",
        "    # yawn early trigger needs FPS -> compute frames threshold now\n",
        "    YAWN_MIN_FRAMES = max(3, int(0.35 * FPS))\n",
        "\n",
        "    face_mesh = mp_face_mesh.FaceMesh(\n",
        "        static_image_mode=False,\n",
        "        max_num_faces=1,\n",
        "        refine_landmarks=True,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5\n",
        "    )\n",
        "\n",
        "    ear_buffer = deque(maxlen=SMOOTHING_WINDOW)\n",
        "    closed_frame_counter = 0\n",
        "    blink_timestamps = deque()\n",
        "    last_alarm_time = 0\n",
        "\n",
        "    # yawn state\n",
        "    mar_buffer = deque(maxlen=MAR_SMOOTHING_WINDOW)\n",
        "    mar_baseline_ring = deque(maxlen=MAR_BASELINE_WINDOW)\n",
        "    yawn_open_frames = 0\n",
        "    last_yawn_alarm_time = 0\n",
        "\n",
        "    print(\"Press 'q' to quit.\")\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"End of video or camera error.\")\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = face_mesh.process(frame_rgb)\n",
        "        h, w = frame.shape[:2]\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            lm = results.multi_face_landmarks[0].landmark\n",
        "            landmarks = [(l.x * w, l.y * h) for l in lm]\n",
        "\n",
        "            # ------------ EAR ------------\n",
        "            left_ear = eye_aspect_ratio(landmarks, LEFT_EYE_IDX)\n",
        "            right_ear = eye_aspect_ratio(landmarks, RIGHT_EYE_IDX)\n",
        "            ear_val = (left_ear + right_ear) / 2.0\n",
        "\n",
        "            ear_buffer.append(ear_val)\n",
        "            ear_smoothed = float(np.mean(ear_buffer))\n",
        "\n",
        "            for idx in LEFT_EYE_IDX + RIGHT_EYE_IDX:\n",
        "                (x, y) = landmarks[idx]\n",
        "                cv2.circle(frame, (int(x), int(y)), 1, (0,255,0), -1)\n",
        "\n",
        "            cv2.putText(frame, f\"EAR: {ear_smoothed:.3f}\", (10,30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)\n",
        "\n",
        "            eye_closed = ear_smoothed < BLINK_DETECTION_EAR_THRESHOLD\n",
        "\n",
        "            if eye_closed:\n",
        "                closed_frame_counter += 1\n",
        "            else:\n",
        "                if closed_frame_counter > 0:\n",
        "                    blink_duration_seconds = closed_frame_counter / FPS\n",
        "                    if 0.05 < blink_duration_seconds < 1.5:\n",
        "                        blink_timestamps.append(time.time())\n",
        "                    closed_frame_counter = 0\n",
        "\n",
        "            current_time = time.time()\n",
        "            while blink_timestamps and (current_time - blink_timestamps[0] > BLINK_WINDOW_SECONDS):\n",
        "                blink_timestamps.popleft()\n",
        "            blinks_per_min = len(blink_timestamps) * (60.0 / BLINK_WINDOW_SECONDS)\n",
        "\n",
        "            cv2.putText(frame, f\"Blinks/min: {blinks_per_min:.1f}\", (10,60),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
        "\n",
        "            # ------------ LOW-LATENCY YAWN ------------\n",
        "            mar_val = mouth_aspect_ratio(landmarks)\n",
        "            mar_buffer.append(mar_val)\n",
        "            mar_smoothed = float(np.mean(mar_buffer))\n",
        "\n",
        "            # learn baseline only when clearly not yawning\n",
        "            provisional_thr = max((np.median(mar_baseline_ring) + MAR_DELTA) if mar_baseline_ring else 0.0, MAR_FLOOR)\n",
        "            if mar_smoothed < provisional_thr:\n",
        "                mar_baseline_ring.append(mar_smoothed)\n",
        "\n",
        "            mar_baseline = np.median(mar_baseline_ring) if mar_baseline_ring else mar_smoothed\n",
        "            enter_thr = max(mar_baseline + MAR_DELTA, MAR_FLOOR)\n",
        "            exit_thr  = max(enter_thr - MAR_HYST, MAR_FLOOR - MAR_HYST)\n",
        "\n",
        "            # hysteresis to avoid flicker\n",
        "            mouth_open = mar_smoothed > (enter_thr if yawn_open_frames == 0 else exit_thr)\n",
        "\n",
        "            if mouth_open:\n",
        "                yawn_open_frames += 1\n",
        "                # fire DURING the yawn (no need to wait for mouth to close)\n",
        "                if (yawn_open_frames >= YAWN_MIN_FRAMES) or ((yawn_open_frames / FPS) >= YAWN_MIN_DURATION):\n",
        "                    if current_time - last_yawn_alarm_time > MIN_BEEP_INTERVAL_YAWN:\n",
        "                        last_yawn_alarm_time = current_time\n",
        "                        cv2.putText(frame, \"YAWN DETECTED!\", (10, 150),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)\n",
        "                        threading.Thread(target=play_alarm_thread, daemon=True).start()\n",
        "            else:\n",
        "                yawn_open_frames = 0\n",
        "\n",
        "            cv2.putText(frame, f\"MAR: {mar_smoothed:.3f} thr:{enter_thr:.2f}\", (10, 90),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 255), 2)\n",
        "\n",
        "            # ------------ Drowsy decision (existing) ------------\n",
        "            is_drowsy_frames = closed_frame_counter >= LONG_FRAME_THRESHOLD\n",
        "            is_drowsy_blinks = blinks_per_min < BLINKS_PER_MIN_THRESHOLD\n",
        "\n",
        "            if is_drowsy_frames or is_drowsy_blinks:\n",
        "                cv2.putText(frame, \"YOU ARE DROWSY!\", (10,110),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3)\n",
        "                if current_time - last_alarm_time > MIN_BEEP_INTERVAL:\n",
        "                    last_alarm_time = current_time\n",
        "                    threading.Thread(target=play_alarm_thread, daemon=True).start()\n",
        "\n",
        "        else:\n",
        "            ear_buffer.clear()\n",
        "            closed_frame_counter = 0\n",
        "            mar_buffer.clear()\n",
        "            mar_baseline_ring.clear()\n",
        "            yawn_open_frames = 0\n",
        "\n",
        "        cv2.imshow(\"Drowsiness Detection\", frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RII3LlYO7U9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}